{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "43b92300",
   "metadata": {},
   "source": [
    "# FinchHealth Assessment\n",
    "**By:** ***Abodunde Ojo***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37ed58d0",
   "metadata": {},
   "source": [
    "#### Import necessary libraries and connect to the postgres engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab8b82f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine, inspect\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy\n",
    "import re\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "nlp = spacy.load('en_core_web_md')# Load spaCy's English language model with NER\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c23a4d3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Engine(postgresql://niphemi.oyewole:***@ep-delicate-river-a5cq94ee-pooler.us-east-2.aws.neon.tech/Vetassist)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "engine = create_engine('postgresql://niphemi.oyewole:W7bHIgaN1ejh@ep-delicate-river-a5cq94ee-pooler.us-east-2.aws.neon.tech/Vetassist')\n",
    "engine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4adb37e3",
   "metadata": {},
   "source": [
    "##### Let us check all the tables in the engine before importing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "57ac9513",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tables in the database:\n",
      "reddit_usernames\n",
      "reddit_usernames_comments\n"
     ]
    }
   ],
   "source": [
    "inspector = inspect(engine)\n",
    "\n",
    "# Get a list of all table names in the database\n",
    "table_names = inspector.get_table_names()\n",
    "\n",
    "# Print the list of table names\n",
    "print(\"Tables in the database:\")\n",
    "for table_name in table_names:\n",
    "    print(table_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1270f6d",
   "metadata": {},
   "source": [
    "We only need the reddit_usernames_comments table for this task. Therefore, we will load only that table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6a0db398",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute a sample query\n",
    "df = pd.read_sql('SELECT * FROM reddit_usernames_comments', con=engine)\n",
    "\n",
    "# Display the first few rows of the DataFrame\n",
    "df.head()\n",
    "\n",
    "engine.dispose()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c19ce93",
   "metadata": {},
   "source": [
    "Let us look at a sample comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "70ae5756",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Female, Kentucky.  4 years out. Work equine only private practice. Base salary $85k plus bonuses/production which was $20k 2023. 6 days a week Jan-June/July then variable in the off season. No limit on PTO - took ~5 weeks last year. One paid conference a year (registration/travel/ 1/2 hotel/ transportation) or online CE program. All licensures & professional group fees covered. Cell phone allowance and mileage reimbursement.|Female, Kentucky.  4 years out. Work equine only private practice. Base salary $85k plus bonuses/production which was $20k 2023. 6 days a week Jan-June/July then variable in the off season. No limit on PTO - took ~5 weeks last year. One paid conference a year (registration/travel/ 1/2 hotel/ transportation) or online CE program. All licensures & professional group fees covered. Cell phone allowance and mileage reimbursement.|Female, Kentucky.  4 years out. Work equine only private practice. Base salary $85k plus bonuses/production which was $20k 2023. 6 days a week Jan-June/July then variable in the off season. No limit on PTO - took ~5 weeks last year. One paid conference a year (registration/travel/ 1/2 hotel/ transportation) or online CE program. All licensures & professional group fees covered. Cell phone allowance and mileage reimbursement.|Female, Kentucky.  4 years out. Work equine only private practice. Base salary $85k plus bonuses/production which was $20k 2023. 6 days a week Jan-June/July then variable in the off season. No limit on PTO - took ~5 weeks last year. One paid conference a year (registration/travel/ 1/2 hotel/ transportation) or online CE program. All licensures & professional group fees covered. Cell phone allowance and mileage reimbursement.|Female, Kentucky.  4 years out. Work equine only private practice. Base salary $85k plus bonuses/production which was $20k 2023. 6 days a week Jan-June/July then variable in the off season. No limit on PTO - took ~5 weeks last year. One paid conference a year (registration/travel/ 1/2 hotel/ transportation) or online CE program. All licensures & professional group fees covered. Cell phone allowance and mileage reimbursement.|Female, Kentucky.  4 years out. Work equine only private practice. Base salary $85k plus bonuses/production which was $20k 2023. 6 days a week Jan-June/July then variable in the off season. No limit on PTO - took ~5 weeks last year. One paid conference a year (registration/travel/ 1/2 hotel/ transportation) or online CE program. All licensures & professional group fees covered. Cell phone allowance and mileage reimbursement.|Female, Kentucky.  4 years out. Work equine only private practice. Base salary $85k plus bonuses/production which was $20k 2023. 6 days a week Jan-June/July then variable in the off season. No limit on PTO - took ~5 weeks last year. One paid conference a year (registration/travel/ 1/2 hotel/ transportation) or online CE program. All licensures & professional group fees covered. Cell phone allowance and mileage reimbursement.|Female, Kentucky.  4 years out. Work equine only private practice. Base salary $85k plus bonuses/production which was $20k 2023. 6 days a week Jan-June/July then variable in the off season. No limit on PTO - took ~5 weeks last year. One paid conference a year (registration/travel/ 1/2 hotel/ transportation) or online CE program. All licensures & professional group fees covered. Cell phone allowance and mileage reimbursement.|Female, Kentucky.  4 years out. Work equine only private practice. Base salary $85k plus bonuses/production which was $20k 2023. 6 days a week Jan-June/July then variable in the off season. No limit on PTO - took ~5 weeks last year. One paid conference a year (registration/travel/ 1/2 hotel/ transportation) or online CE program. All licensures & professional group fees covered. Cell phone allowance and mileage reimbursement.|Female, Kentucky.  4 years out. Work equine only private practice. Base salary $85k plus bonuses/production which was $20k 2023. 6 days a week Jan-June/July then variable in the off season. No limit on PTO - took ~5 weeks last year. One paid conference a year (registration/travel/ 1/2 hotel/ transportation) or online CE program. All licensures & professional group fees covered. Cell phone allowance and mileage reimbursement.|Female, Kentucky.  4 years out. Work equine only private practice. Base salary $85k plus bonuses/production which was $20k 2023. 6 days a week Jan-June/July then variable in the off season. No limit on PTO - took ~5 weeks last year. One paid conference a year (registration/travel/ 1/2 hotel/ transportation) or online CE program. All licensures & professional group fees covered. Cell phone allowance and mileage reimbursement.|Female, Kentucky.  4 years out. Work equine only private practice. Base salary $85k plus bonuses/production which was $20k 2023. 6 days a week Jan-June/July then variable in the off season. No limit on PTO - took ~5 weeks last year. One paid conference a year (registration/travel/ 1/2 hotel/ transportation) or online CE program. All licensures & professional group fees covered. Cell phone allowance and mileage reimbursement.|Female, Kentucky.  4 years out. Work equine only private practice. Base salary $85k plus bonuses/production which was $20k 2023. 6 days a week Jan-June/July then variable in the off season. No limit on PTO - took ~5 weeks last year. One paid conference a year (registration/travel/ 1/2 hotel/ transportation) or online CE program. All licensures & professional group fees covered. Cell phone allowance and mileage reimbursement.|Female, Kentucky.  4 years out. Work equine only private practice. Base salary $85k plus bonuses/production which was $20k 2023. 6 days a week Jan-June/July then variable in the off season. No limit on PTO - took ~5 weeks last year. One paid conference a year (registration/travel/ 1/2 hotel/ transportation) or online CE program. All licensures & professional group fees covered. Cell phone allowance and mileage reimbursement.|Female, Kentucky.  4 years out. Work equine only private practice. Base salary $85k plus bonuses/production which was $20k 2023. 6 days a week Jan-June/July then variable in the off season. No limit on PTO - took ~5 weeks last year. One paid conference a year (registration/travel/ 1/2 hotel/ transportation) or online CE program. All licensures & professional group fees covered. Cell phone allowance and mileage reimbursement.|Female, Kentucky.  4 years out. Work equine only private practice. Base salary $85k plus bonuses/production which was $20k 2023. 6 days a week Jan-June/July then variable in the off season. No limit on PTO - took ~5 weeks last year. One paid conference a year (registration/travel/ 1/2 hotel/ transportation) or online CE program. All licensures & professional group fees covered. Cell phone allowance and mileage reimbursement.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.comments[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9dfe61d",
   "metadata": {},
   "source": [
    "The comments seem repeated One of the things we will do is clean each comment to remove repetition. As we can see, each repetition seems to be split by \"|\". We will split on this delimiter and return only the first one. **For this we can write a simple function** but before then,we can check this assumption."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3aa4d4e",
   "metadata": {},
   "source": [
    "**Assert**: We can check to confirm that the comments are indeed repeated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ae0b9932",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df.comments[1].split(\"|\")\n",
    "assert data[0] == data[1] == data[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "860e191c",
   "metadata": {},
   "source": [
    "**Result**: As we can see, an assertion error does not occur. We can then assume that this is the structure of the comments for all comments in the table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1e648576",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trim_comments(x):\n",
    "    data = x.split(\"|\")\n",
    "    data = data[0] #That is, extract only the first instance of the comment.\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "151fe8d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Female, Kentucky.  4 years out. Work equine only private practice. Base salary $85k plus bonuses/production which was $20k 2023. 6 days a week Jan-June/July then variable in the off season. No limit on PTO - took ~5 weeks last year. One paid conference a year (registration/travel/ 1/2 hotel/ transportation) or online CE program. All licensures & professional group fees covered. Cell phone allowance and mileage reimbursement.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Let us see how it works\n",
    "data = trim_comments(df.comments[0])\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74379cc2",
   "metadata": {},
   "source": [
    "###### We can subsequently apply this trimming to the whole dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4192988e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"trimmed_comments\"] = df[\"comments\"].apply(trim_comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a5f9a654",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>username</th>\n",
       "      <th>comments</th>\n",
       "      <th>created_at</th>\n",
       "      <th>tags</th>\n",
       "      <th>url</th>\n",
       "      <th>trimmed_comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LoveAGoodTwist</td>\n",
       "      <td>Female, Kentucky.  4 years out. Work equine on...</td>\n",
       "      <td>2024-05-18 22:37:09.776679</td>\n",
       "      <td>[]</td>\n",
       "      <td>n/a</td>\n",
       "      <td>Female, Kentucky.  4 years out. Work equine on...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>wahznooski</td>\n",
       "      <td>As a woman of reproductive age, fuck Texas|As ...</td>\n",
       "      <td>2024-05-18 22:37:09.776679</td>\n",
       "      <td>[]</td>\n",
       "      <td>n/a</td>\n",
       "      <td>As a woman of reproductive age, fuck Texas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Churro_The_fish_Girl</td>\n",
       "      <td>what makes you want to become a vet?|what make...</td>\n",
       "      <td>2024-05-18 22:37:09.776679</td>\n",
       "      <td>[]</td>\n",
       "      <td>n/a</td>\n",
       "      <td>what makes you want to become a vet?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>abarthch</td>\n",
       "      <td>I see of course there are changing variables, ...</td>\n",
       "      <td>2024-05-18 22:37:09.776679</td>\n",
       "      <td>[]</td>\n",
       "      <td>n/a</td>\n",
       "      <td>I see of course there are changing variables, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>queerofengland</td>\n",
       "      <td>Contrary to employers' belief, at will does no...</td>\n",
       "      <td>2024-05-18 22:37:09.776679</td>\n",
       "      <td>[]</td>\n",
       "      <td>n/a</td>\n",
       "      <td>Contrary to employers' belief, at will does no...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3271</th>\n",
       "      <td>B1u3Chips_</td>\n",
       "      <td>I’m looking into applying for veterinary nursi...</td>\n",
       "      <td>2024-05-18 22:37:09.776679</td>\n",
       "      <td>[]</td>\n",
       "      <td>n/a</td>\n",
       "      <td>I’m looking into applying for veterinary nursi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3272</th>\n",
       "      <td>Daktari2018</td>\n",
       "      <td>Good for you for sticking to standards of care...</td>\n",
       "      <td>2024-05-18 22:37:09.776679</td>\n",
       "      <td>[]</td>\n",
       "      <td>n/a</td>\n",
       "      <td>Good for you for sticking to standards of care...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3273</th>\n",
       "      <td>Sheepb1</td>\n",
       "      <td>Yes feel free to ask someone to double check, ...</td>\n",
       "      <td>2024-05-18 22:37:09.776679</td>\n",
       "      <td>[]</td>\n",
       "      <td>n/a</td>\n",
       "      <td>Yes feel free to ask someone to double check, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3274</th>\n",
       "      <td>Elyrath</td>\n",
       "      <td>Same! Helps massively. Errors can still occur,...</td>\n",
       "      <td>2024-05-18 22:37:09.776679</td>\n",
       "      <td>[]</td>\n",
       "      <td>n/a</td>\n",
       "      <td>Same! Helps massively. Errors can still occur,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3275</th>\n",
       "      <td>Real_Use_3216</td>\n",
       "      <td>It’s no different than undergrad. School is sc...</td>\n",
       "      <td>2024-05-18 22:37:09.776679</td>\n",
       "      <td>[]</td>\n",
       "      <td>n/a</td>\n",
       "      <td>It’s no different than undergrad. School is sc...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3276 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  username                                           comments  \\\n",
       "0           LoveAGoodTwist  Female, Kentucky.  4 years out. Work equine on...   \n",
       "1               wahznooski  As a woman of reproductive age, fuck Texas|As ...   \n",
       "2     Churro_The_fish_Girl  what makes you want to become a vet?|what make...   \n",
       "3                 abarthch  I see of course there are changing variables, ...   \n",
       "4           queerofengland  Contrary to employers' belief, at will does no...   \n",
       "...                    ...                                                ...   \n",
       "3271            B1u3Chips_  I’m looking into applying for veterinary nursi...   \n",
       "3272           Daktari2018  Good for you for sticking to standards of care...   \n",
       "3273               Sheepb1  Yes feel free to ask someone to double check, ...   \n",
       "3274               Elyrath  Same! Helps massively. Errors can still occur,...   \n",
       "3275         Real_Use_3216  It’s no different than undergrad. School is sc...   \n",
       "\n",
       "                     created_at tags  url  \\\n",
       "0    2024-05-18 22:37:09.776679   []  n/a   \n",
       "1    2024-05-18 22:37:09.776679   []  n/a   \n",
       "2    2024-05-18 22:37:09.776679   []  n/a   \n",
       "3    2024-05-18 22:37:09.776679   []  n/a   \n",
       "4    2024-05-18 22:37:09.776679   []  n/a   \n",
       "...                         ...  ...  ...   \n",
       "3271 2024-05-18 22:37:09.776679   []  n/a   \n",
       "3272 2024-05-18 22:37:09.776679   []  n/a   \n",
       "3273 2024-05-18 22:37:09.776679   []  n/a   \n",
       "3274 2024-05-18 22:37:09.776679   []  n/a   \n",
       "3275 2024-05-18 22:37:09.776679   []  n/a   \n",
       "\n",
       "                                       trimmed_comments  \n",
       "0     Female, Kentucky.  4 years out. Work equine on...  \n",
       "1            As a woman of reproductive age, fuck Texas  \n",
       "2                  what makes you want to become a vet?  \n",
       "3     I see of course there are changing variables, ...  \n",
       "4     Contrary to employers' belief, at will does no...  \n",
       "...                                                 ...  \n",
       "3271  I’m looking into applying for veterinary nursi...  \n",
       "3272  Good for you for sticking to standards of care...  \n",
       "3273  Yes feel free to ask someone to double check, ...  \n",
       "3274  Same! Helps massively. Errors can still occur,...  \n",
       "3275  It’s no different than undergrad. School is sc...  \n",
       "\n",
       "[3276 rows x 6 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "995f7ecd",
   "metadata": {},
   "source": [
    "#### Drop the initial comments column only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b68c722f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df.drop(\"comments\", axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dbe094b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>username</th>\n",
       "      <th>created_at</th>\n",
       "      <th>tags</th>\n",
       "      <th>url</th>\n",
       "      <th>trimmed_comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LoveAGoodTwist</td>\n",
       "      <td>2024-05-18 22:37:09.776679</td>\n",
       "      <td>[]</td>\n",
       "      <td>n/a</td>\n",
       "      <td>Female, Kentucky.  4 years out. Work equine on...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>wahznooski</td>\n",
       "      <td>2024-05-18 22:37:09.776679</td>\n",
       "      <td>[]</td>\n",
       "      <td>n/a</td>\n",
       "      <td>As a woman of reproductive age, fuck Texas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Churro_The_fish_Girl</td>\n",
       "      <td>2024-05-18 22:37:09.776679</td>\n",
       "      <td>[]</td>\n",
       "      <td>n/a</td>\n",
       "      <td>what makes you want to become a vet?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>abarthch</td>\n",
       "      <td>2024-05-18 22:37:09.776679</td>\n",
       "      <td>[]</td>\n",
       "      <td>n/a</td>\n",
       "      <td>I see of course there are changing variables, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>queerofengland</td>\n",
       "      <td>2024-05-18 22:37:09.776679</td>\n",
       "      <td>[]</td>\n",
       "      <td>n/a</td>\n",
       "      <td>Contrary to employers' belief, at will does no...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3271</th>\n",
       "      <td>B1u3Chips_</td>\n",
       "      <td>2024-05-18 22:37:09.776679</td>\n",
       "      <td>[]</td>\n",
       "      <td>n/a</td>\n",
       "      <td>I’m looking into applying for veterinary nursi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3272</th>\n",
       "      <td>Daktari2018</td>\n",
       "      <td>2024-05-18 22:37:09.776679</td>\n",
       "      <td>[]</td>\n",
       "      <td>n/a</td>\n",
       "      <td>Good for you for sticking to standards of care...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3273</th>\n",
       "      <td>Sheepb1</td>\n",
       "      <td>2024-05-18 22:37:09.776679</td>\n",
       "      <td>[]</td>\n",
       "      <td>n/a</td>\n",
       "      <td>Yes feel free to ask someone to double check, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3274</th>\n",
       "      <td>Elyrath</td>\n",
       "      <td>2024-05-18 22:37:09.776679</td>\n",
       "      <td>[]</td>\n",
       "      <td>n/a</td>\n",
       "      <td>Same! Helps massively. Errors can still occur,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3275</th>\n",
       "      <td>Real_Use_3216</td>\n",
       "      <td>2024-05-18 22:37:09.776679</td>\n",
       "      <td>[]</td>\n",
       "      <td>n/a</td>\n",
       "      <td>It’s no different than undergrad. School is sc...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3276 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  username                 created_at tags  url  \\\n",
       "0           LoveAGoodTwist 2024-05-18 22:37:09.776679   []  n/a   \n",
       "1               wahznooski 2024-05-18 22:37:09.776679   []  n/a   \n",
       "2     Churro_The_fish_Girl 2024-05-18 22:37:09.776679   []  n/a   \n",
       "3                 abarthch 2024-05-18 22:37:09.776679   []  n/a   \n",
       "4           queerofengland 2024-05-18 22:37:09.776679   []  n/a   \n",
       "...                    ...                        ...  ...  ...   \n",
       "3271            B1u3Chips_ 2024-05-18 22:37:09.776679   []  n/a   \n",
       "3272           Daktari2018 2024-05-18 22:37:09.776679   []  n/a   \n",
       "3273               Sheepb1 2024-05-18 22:37:09.776679   []  n/a   \n",
       "3274               Elyrath 2024-05-18 22:37:09.776679   []  n/a   \n",
       "3275         Real_Use_3216 2024-05-18 22:37:09.776679   []  n/a   \n",
       "\n",
       "                                       trimmed_comments  \n",
       "0     Female, Kentucky.  4 years out. Work equine on...  \n",
       "1            As a woman of reproductive age, fuck Texas  \n",
       "2                  what makes you want to become a vet?  \n",
       "3     I see of course there are changing variables, ...  \n",
       "4     Contrary to employers' belief, at will does no...  \n",
       "...                                                 ...  \n",
       "3271  I’m looking into applying for veterinary nursi...  \n",
       "3272  Good for you for sticking to standards of care...  \n",
       "3273  Yes feel free to ask someone to double check, ...  \n",
       "3274  Same! Helps massively. Errors can still occur,...  \n",
       "3275  It’s no different than undergrad. School is sc...  \n",
       "\n",
       "[3276 rows x 5 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65597eef",
   "metadata": {},
   "source": [
    "##### Next we preporcess the Dataset.\n",
    "This includes lowercase conversion, and removal of stopwords and special characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0a22ccc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We define the preprocessing function\n",
    "\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "def preprocess_text(text):\n",
    "    text = text.lower() #lowercase conversion\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text) #removal of special characters\n",
    "    tokens = word_tokenize(text) #tokenization of the text\n",
    "    \n",
    "    stop_words = set(stopwords.words('english')) #load the stopword instance\n",
    "    filtered_tokens = [token for token in tokens if token not in stop_words] #remove stopwords\n",
    "    \n",
    "    preprocessed_text = ' '.join(filtered_tokens) # Join the tokens back into a single string\n",
    "    \n",
    "    return preprocessed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a00305dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1[\"processed_text\"] = df1[\"trimmed_comments\"].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "99dd4d36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>username</th>\n",
       "      <th>created_at</th>\n",
       "      <th>tags</th>\n",
       "      <th>url</th>\n",
       "      <th>trimmed_comments</th>\n",
       "      <th>processed_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LoveAGoodTwist</td>\n",
       "      <td>2024-05-18 22:37:09.776679</td>\n",
       "      <td>[]</td>\n",
       "      <td>n/a</td>\n",
       "      <td>Female, Kentucky.  4 years out. Work equine on...</td>\n",
       "      <td>female kentucky years work equine private prac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>wahznooski</td>\n",
       "      <td>2024-05-18 22:37:09.776679</td>\n",
       "      <td>[]</td>\n",
       "      <td>n/a</td>\n",
       "      <td>As a woman of reproductive age, fuck Texas</td>\n",
       "      <td>woman reproductive age fuck texas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Churro_The_fish_Girl</td>\n",
       "      <td>2024-05-18 22:37:09.776679</td>\n",
       "      <td>[]</td>\n",
       "      <td>n/a</td>\n",
       "      <td>what makes you want to become a vet?</td>\n",
       "      <td>makes want become vet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>abarthch</td>\n",
       "      <td>2024-05-18 22:37:09.776679</td>\n",
       "      <td>[]</td>\n",
       "      <td>n/a</td>\n",
       "      <td>I see of course there are changing variables, ...</td>\n",
       "      <td>see course changing variables dimension change...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>queerofengland</td>\n",
       "      <td>2024-05-18 22:37:09.776679</td>\n",
       "      <td>[]</td>\n",
       "      <td>n/a</td>\n",
       "      <td>Contrary to employers' belief, at will does no...</td>\n",
       "      <td>contrary employers belief actually mean fired ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3271</th>\n",
       "      <td>B1u3Chips_</td>\n",
       "      <td>2024-05-18 22:37:09.776679</td>\n",
       "      <td>[]</td>\n",
       "      <td>n/a</td>\n",
       "      <td>I’m looking into applying for veterinary nursi...</td>\n",
       "      <td>im looking applying veterinary nursing college...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3272</th>\n",
       "      <td>Daktari2018</td>\n",
       "      <td>2024-05-18 22:37:09.776679</td>\n",
       "      <td>[]</td>\n",
       "      <td>n/a</td>\n",
       "      <td>Good for you for sticking to standards of care...</td>\n",
       "      <td>good sticking standards care caring enough spe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3273</th>\n",
       "      <td>Sheepb1</td>\n",
       "      <td>2024-05-18 22:37:09.776679</td>\n",
       "      <td>[]</td>\n",
       "      <td>n/a</td>\n",
       "      <td>Yes feel free to ask someone to double check, ...</td>\n",
       "      <td>yes feel free ask someone double check used wo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3274</th>\n",
       "      <td>Elyrath</td>\n",
       "      <td>2024-05-18 22:37:09.776679</td>\n",
       "      <td>[]</td>\n",
       "      <td>n/a</td>\n",
       "      <td>Same! Helps massively. Errors can still occur,...</td>\n",
       "      <td>helps massively errors still occur signficantl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3275</th>\n",
       "      <td>Real_Use_3216</td>\n",
       "      <td>2024-05-18 22:37:09.776679</td>\n",
       "      <td>[]</td>\n",
       "      <td>n/a</td>\n",
       "      <td>It’s no different than undergrad. School is sc...</td>\n",
       "      <td>different undergrad school school</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3276 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  username                 created_at tags  url  \\\n",
       "0           LoveAGoodTwist 2024-05-18 22:37:09.776679   []  n/a   \n",
       "1               wahznooski 2024-05-18 22:37:09.776679   []  n/a   \n",
       "2     Churro_The_fish_Girl 2024-05-18 22:37:09.776679   []  n/a   \n",
       "3                 abarthch 2024-05-18 22:37:09.776679   []  n/a   \n",
       "4           queerofengland 2024-05-18 22:37:09.776679   []  n/a   \n",
       "...                    ...                        ...  ...  ...   \n",
       "3271            B1u3Chips_ 2024-05-18 22:37:09.776679   []  n/a   \n",
       "3272           Daktari2018 2024-05-18 22:37:09.776679   []  n/a   \n",
       "3273               Sheepb1 2024-05-18 22:37:09.776679   []  n/a   \n",
       "3274               Elyrath 2024-05-18 22:37:09.776679   []  n/a   \n",
       "3275         Real_Use_3216 2024-05-18 22:37:09.776679   []  n/a   \n",
       "\n",
       "                                       trimmed_comments  \\\n",
       "0     Female, Kentucky.  4 years out. Work equine on...   \n",
       "1            As a woman of reproductive age, fuck Texas   \n",
       "2                  what makes you want to become a vet?   \n",
       "3     I see of course there are changing variables, ...   \n",
       "4     Contrary to employers' belief, at will does no...   \n",
       "...                                                 ...   \n",
       "3271  I’m looking into applying for veterinary nursi...   \n",
       "3272  Good for you for sticking to standards of care...   \n",
       "3273  Yes feel free to ask someone to double check, ...   \n",
       "3274  Same! Helps massively. Errors can still occur,...   \n",
       "3275  It’s no different than undergrad. School is sc...   \n",
       "\n",
       "                                         processed_text  \n",
       "0     female kentucky years work equine private prac...  \n",
       "1                     woman reproductive age fuck texas  \n",
       "2                                 makes want become vet  \n",
       "3     see course changing variables dimension change...  \n",
       "4     contrary employers belief actually mean fired ...  \n",
       "...                                                 ...  \n",
       "3271  im looking applying veterinary nursing college...  \n",
       "3272  good sticking standards care caring enough spe...  \n",
       "3273  yes feel free ask someone double check used wo...  \n",
       "3274  helps massively errors still occur signficantl...  \n",
       "3275                  different undergrad school school  \n",
       "\n",
       "[3276 rows x 6 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8497a11e",
   "metadata": {},
   "outputs": [],
   "source": [
    "maximum_similarity = []\n",
    "for word in df1[\"processed_text\"][0].split():\n",
    "    maximum_similarity.append(nlp(\"veterinarian\").similarity(nlp(word)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b720ba05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0000000713113224"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(maximum_similarity)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6def5888",
   "metadata": {},
   "source": [
    "### Let us restate the Task Requirements\n",
    "**Main Task:** Create a classifier that will accurately classify a list of reddit comments into the proper labels.\n",
    "\n",
    "**Additional criteria:**\n",
    "\n",
    "Your classifier should run through this list and determine if they are of these categories:\n",
    "\n",
    "**Medical Doctor**\n",
    "These should only include practicing doctors, medical school students or nurses or medical professionals who aren’t doctors should go into the “other” label\n",
    "\n",
    "**Veterinarian**\n",
    "These should only include practicing vets, vet students or vet techs should go into the “other” label\n",
    "\n",
    "**Other**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a48c8f38",
   "metadata": {},
   "source": [
    "### Considerations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21d6d3c1",
   "metadata": {},
   "source": [
    "The task itself has asked for a classifier. Now, ***classifiers*** in the context of machine learning could mean to create a classification algorithm like a logistic regression or a neural network that would automatically assign values to the text data based on a pretrained knowledge. However, to achieve this task, some sort of labelling must have been done. Since we do not have labels, we can autogenrate labels using different methods. ***we will get back to this shortly***.\n",
    "\n",
    "This leads us to the second task which is autogenerating labels for each comment based on the stringent rules that have been set. There are multiple ways to go about this. We will focus on four and choose the best two for this task.\n",
    "\n",
    "***Manual Labelling***: *This involves manually reading each Reddit comment and assigning the appropriate label based on its content or context. We have over 3000 comments. This is unrealistic*\n",
    "\n",
    "***Semi-Supervised Learning***: *This involves manually labelling a small subset of the dataset. Afterwards we can use semi-supervised learning techniques to bootstrap the labeling process. The manual intervention might also defeat the purpose of the task*\n",
    "\n",
    "***Named Entity Recognision (NER)/Cosine Similarity***: *This can be an effective approach for labeling Reddit comments, especially  since we're interested in identifying specific entities mentioned in the comments. NER can automatically identify and classify named entities such as persons, organizations, locations, dates, and more within text data. This will also involve semantic similarity checks that we can do on the dataset*\n",
    "\n",
    "***Regular Expression***: *This involves setting a classification criteria and looping through each of the comments to check if the classification criteria is correct*\n",
    "\n",
    "***We will focus on synthesizing the last two approaches for a robust outcome***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4cfa0c9",
   "metadata": {},
   "source": [
    "### Labelling The Comments\n",
    "\n",
    "But first, let us define the functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "04cc1e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialise key words to check and drop\n",
    "medical_doctor_regex = re.compile(r'\\b(medical student|nurse)\\b', flags=re.IGNORECASE)\n",
    "    \n",
    "veterinarian_regex = re.compile(r'\\b(vet student|vet tech)\\b', flags=re.IGNORECASE)\n",
    "\n",
    "def other_words_check(comment, keyword):\n",
    "    \"\"\"\n",
    "    This function uses regular expression to implement a check to see if a particular buzz word is \n",
    "    \"\"\"\n",
    "    if keyword == 'doctor':\n",
    "         if medical_doctor_regex.search(comment):\n",
    "                return True\n",
    "    elif keyword == 'veterinarian':\n",
    "        if veterinarian_regex.search(comment):\n",
    "            return True\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "    \n",
    "\n",
    "def get_related_keywords(word):\n",
    "    \"\"\"\n",
    "    This function is used to get all key words (synonyms and antonyms)\n",
    "    for a particular word. Since we are trying to remove instances where they are students or nurses, \n",
    "    this might come in handy comes in handy. \n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    synonyms = set()\n",
    "    antonyms = set()\n",
    "\n",
    "    # Iterate over each synset (a set of synonyms) of the word in WordNet\n",
    "    for synset in wordnet.synsets(word):\n",
    "        # Add synonyms of the word\n",
    "        synonyms.update(synset.lemma_names())\n",
    "\n",
    "        # Add antonyms of the word (if available)\n",
    "        for lemma in synset.lemmas():\n",
    "            if lemma.antonyms():\n",
    "                antonyms.update(lemma.antonyms()[0].name())\n",
    "\n",
    "    return synonyms, antonyms\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def similarity_check(keyword, x):\n",
    "    \n",
    "    keywords = get_related_keywords(keyword)[0] #get all key words and related synonyms\n",
    "    similarity = []\n",
    "    sentence = x.split()\n",
    "    sentence = [word if word in keywords else word for word in sentence] #replacing all synonyms of the keyword with keyword itself\n",
    "    sentence1 = ' '.join(sentence)#######\n",
    "    other_inquiry = other_words_check(sentence1, keyword)\n",
    "    student_synonyms = get_related_keywords(\"student\")[0] #Get all synonyms of student\n",
    "    \n",
    "    \n",
    "    \n",
    "    for word in sentence:\n",
    "        if word in student_synonyms or other_inquiry:\n",
    "                return 0\n",
    "        else:\n",
    "            similarity.append(nlp(keyword.lower()).similarity(nlp(word))) #check the similarity between the keyword and each word in the reddit comment\n",
    "             \n",
    "    \n",
    "    similarity = max(similarity) if similarity else 0\n",
    "    if similarity >=0.70:\n",
    "        return keyword\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7972ea4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf = \"I am a student vet\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "49be5f58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'veterinarian'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity_check(keyword = \"veterinarian\", x=df1[\"processed_text\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0e849706",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity_check(keyword = \"veterinarian\", x=sdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63f3dbc9",
   "metadata": {},
   "source": [
    "**Add new columns to the dataframe**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "708460b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1[\"veterinary_label\"] = df1[\"processed_text\"].apply(lambda row: similarity_check(keyword = \"veterinarian\", x = row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "774dcd94",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1[\"doctor_label\"] = df1[\"processed_text\"].apply(lambda row: similarity_check(keyword = \"doctor\", x = row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8ff8ad64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0               3019\n",
       "veterinarian     257\n",
       "Name: veterinary_label, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.veterinary_label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7e80ace4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>username</th>\n",
       "      <th>created_at</th>\n",
       "      <th>tags</th>\n",
       "      <th>url</th>\n",
       "      <th>trimmed_comments</th>\n",
       "      <th>processed_text</th>\n",
       "      <th>veterinary_label</th>\n",
       "      <th>doctor_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LoveAGoodTwist</td>\n",
       "      <td>2024-05-18 22:37:09.776679</td>\n",
       "      <td>[]</td>\n",
       "      <td>n/a</td>\n",
       "      <td>Female, Kentucky.  4 years out. Work equine on...</td>\n",
       "      <td>female kentucky years work equine private prac...</td>\n",
       "      <td>veterinarian</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>wahznooski</td>\n",
       "      <td>2024-05-18 22:37:09.776679</td>\n",
       "      <td>[]</td>\n",
       "      <td>n/a</td>\n",
       "      <td>As a woman of reproductive age, fuck Texas</td>\n",
       "      <td>woman reproductive age fuck texas</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Churro_The_fish_Girl</td>\n",
       "      <td>2024-05-18 22:37:09.776679</td>\n",
       "      <td>[]</td>\n",
       "      <td>n/a</td>\n",
       "      <td>what makes you want to become a vet?</td>\n",
       "      <td>makes want become vet</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>abarthch</td>\n",
       "      <td>2024-05-18 22:37:09.776679</td>\n",
       "      <td>[]</td>\n",
       "      <td>n/a</td>\n",
       "      <td>I see of course there are changing variables, ...</td>\n",
       "      <td>see course changing variables dimension change...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>queerofengland</td>\n",
       "      <td>2024-05-18 22:37:09.776679</td>\n",
       "      <td>[]</td>\n",
       "      <td>n/a</td>\n",
       "      <td>Contrary to employers' belief, at will does no...</td>\n",
       "      <td>contrary employers belief actually mean fired ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3271</th>\n",
       "      <td>B1u3Chips_</td>\n",
       "      <td>2024-05-18 22:37:09.776679</td>\n",
       "      <td>[]</td>\n",
       "      <td>n/a</td>\n",
       "      <td>I’m looking into applying for veterinary nursi...</td>\n",
       "      <td>im looking applying veterinary nursing college...</td>\n",
       "      <td>veterinarian</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3272</th>\n",
       "      <td>Daktari2018</td>\n",
       "      <td>2024-05-18 22:37:09.776679</td>\n",
       "      <td>[]</td>\n",
       "      <td>n/a</td>\n",
       "      <td>Good for you for sticking to standards of care...</td>\n",
       "      <td>good sticking standards care caring enough spe...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3273</th>\n",
       "      <td>Sheepb1</td>\n",
       "      <td>2024-05-18 22:37:09.776679</td>\n",
       "      <td>[]</td>\n",
       "      <td>n/a</td>\n",
       "      <td>Yes feel free to ask someone to double check, ...</td>\n",
       "      <td>yes feel free ask someone double check used wo...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3274</th>\n",
       "      <td>Elyrath</td>\n",
       "      <td>2024-05-18 22:37:09.776679</td>\n",
       "      <td>[]</td>\n",
       "      <td>n/a</td>\n",
       "      <td>Same! Helps massively. Errors can still occur,...</td>\n",
       "      <td>helps massively errors still occur signficantl...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3275</th>\n",
       "      <td>Real_Use_3216</td>\n",
       "      <td>2024-05-18 22:37:09.776679</td>\n",
       "      <td>[]</td>\n",
       "      <td>n/a</td>\n",
       "      <td>It’s no different than undergrad. School is sc...</td>\n",
       "      <td>different undergrad school school</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3276 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  username                 created_at tags  url  \\\n",
       "0           LoveAGoodTwist 2024-05-18 22:37:09.776679   []  n/a   \n",
       "1               wahznooski 2024-05-18 22:37:09.776679   []  n/a   \n",
       "2     Churro_The_fish_Girl 2024-05-18 22:37:09.776679   []  n/a   \n",
       "3                 abarthch 2024-05-18 22:37:09.776679   []  n/a   \n",
       "4           queerofengland 2024-05-18 22:37:09.776679   []  n/a   \n",
       "...                    ...                        ...  ...  ...   \n",
       "3271            B1u3Chips_ 2024-05-18 22:37:09.776679   []  n/a   \n",
       "3272           Daktari2018 2024-05-18 22:37:09.776679   []  n/a   \n",
       "3273               Sheepb1 2024-05-18 22:37:09.776679   []  n/a   \n",
       "3274               Elyrath 2024-05-18 22:37:09.776679   []  n/a   \n",
       "3275         Real_Use_3216 2024-05-18 22:37:09.776679   []  n/a   \n",
       "\n",
       "                                       trimmed_comments  \\\n",
       "0     Female, Kentucky.  4 years out. Work equine on...   \n",
       "1            As a woman of reproductive age, fuck Texas   \n",
       "2                  what makes you want to become a vet?   \n",
       "3     I see of course there are changing variables, ...   \n",
       "4     Contrary to employers' belief, at will does no...   \n",
       "...                                                 ...   \n",
       "3271  I’m looking into applying for veterinary nursi...   \n",
       "3272  Good for you for sticking to standards of care...   \n",
       "3273  Yes feel free to ask someone to double check, ...   \n",
       "3274  Same! Helps massively. Errors can still occur,...   \n",
       "3275  It’s no different than undergrad. School is sc...   \n",
       "\n",
       "                                         processed_text veterinary_label  \\\n",
       "0     female kentucky years work equine private prac...     veterinarian   \n",
       "1                     woman reproductive age fuck texas                0   \n",
       "2                                 makes want become vet                0   \n",
       "3     see course changing variables dimension change...                0   \n",
       "4     contrary employers belief actually mean fired ...                0   \n",
       "...                                                 ...              ...   \n",
       "3271  im looking applying veterinary nursing college...     veterinarian   \n",
       "3272  good sticking standards care caring enough spe...                0   \n",
       "3273  yes feel free ask someone double check used wo...                0   \n",
       "3274  helps massively errors still occur signficantl...                0   \n",
       "3275                  different undergrad school school                0   \n",
       "\n",
       "     doctor_label  \n",
       "0               0  \n",
       "1               0  \n",
       "2               0  \n",
       "3               0  \n",
       "4               0  \n",
       "...           ...  \n",
       "3271            0  \n",
       "3272            0  \n",
       "3273            0  \n",
       "3274            0  \n",
       "3275            0  \n",
       "\n",
       "[3276 rows x 8 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a634b6cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         3095\n",
       "doctor     181\n",
       "Name: doctor_label, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.doctor_label.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63ae838a",
   "metadata": {},
   "source": [
    "### Let us Assign a final Label\n",
    "\n",
    "With the way we have structured the logic, there are possible instances where the check would pass for both veterinarian and doctor. We will prioritize veterinarian in these scenarios, We can write a simple function for this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ea995d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_assignment(row):\n",
    "    veterinary_label = str(row[\"veterinary_label\"])\n",
    "    doctor_label = str(row[\"doctor_label\"])\n",
    "    \n",
    "    if veterinary_label == \"0\" and doctor_label == \"0\":\n",
    "        return \"others\"\n",
    "    elif veterinary_label != \"0\" and doctor_label != \"0\":\n",
    "        return veterinary_label\n",
    "    else:\n",
    "        return doctor_label if doctor_label != \"0\" else veterinary_label\n",
    "\n",
    "# Here we apply the label_assignment function to create a new column\n",
    "df1[\"label\"] = df1.apply(label_assignment, axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c7cd598f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "others          2874\n",
       "veterinarian     257\n",
       "doctor           145\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The distribution of the labels in the dataset\n",
    "df1.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "40cd78ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the dataset to a datafram\n",
    "\n",
    "df1.to_csv(\"reddit_labelled.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad8a0d73",
   "metadata": {},
   "source": [
    "### Extreme Gradient Boosting (XGBoost) Algorithm\n",
    "Since we have our lable, we can look to train (basic model, no tuning) labelled data  on a subset of the dataset and check the performance on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3583768b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "26407622",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(df1[\"processed_text\"], df1[\"label\"], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "07e2e267",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorize the preprocessed comments\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_train_vectorized = vectorizer.fit_transform(X_train)\n",
    "X_test_vectorized = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fa6d5a6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.975609756097561\n"
     ]
    }
   ],
   "source": [
    "# Initialize LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Encode the class labels\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "y_test_encoded = label_encoder.transform(y_test)\n",
    "\n",
    "# Initialize XGBoost classifier\n",
    "classifier = XGBClassifier()\n",
    "\n",
    "# Train the classifier on the training data\n",
    "classifier.fit(X_train_vectorized, y_train_encoded)\n",
    "\n",
    "# Predict on the testing data\n",
    "y_pred_encoded = classifier.predict(X_test_vectorized)\n",
    "\n",
    "# Decode the predicted labels\n",
    "y_pred = label_encoder.inverse_transform(y_pred_encoded)\n",
    "\n",
    "# Evaluate the classifier\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0e56bd97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>27</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>562</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    0    1   2\n",
       "0  27    6   1\n",
       "1   1  562   5\n",
       "2   0    3  51"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "pd.DataFrame(conf_matrix)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "09babedf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      doctor       0.96      0.79      0.87        34\n",
      "      others       0.98      0.99      0.99       568\n",
      "veterinarian       0.89      0.94      0.92        54\n",
      "\n",
      "    accuracy                           0.98       656\n",
      "   macro avg       0.95      0.91      0.93       656\n",
      "weighted avg       0.98      0.98      0.98       656\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculate precision, recall, and F1-score\n",
    "report = classification_report(y_test, y_pred)\n",
    "print(\"Classification Report:\")\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a3f15af6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['vectorizer.pkl']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Save the trained model to a file\n",
    "joblib.dump(classifier, 'xgboost_model.pkl')\n",
    "\n",
    "#save the encoder\n",
    "joblib.dump(label_encoder, 'label_encoder.pkl')\n",
    "\n",
    "#save the vectorizer\n",
    "joblib.dump(vectorizer, 'vectorizer.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a12a47aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "eb02e812",
   "metadata": {},
   "source": [
    "##### Save the models into a model pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc0babfd",
   "metadata": {},
   "source": [
    "###### The preprocessing step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7ba70bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('stopwords')\n",
    "\n",
    "class TextPreprocessor(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        self.stop_words = set(stopwords.words('english'))\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self  # Nothing to fit\n",
    "\n",
    "    def transform(self, X):\n",
    "        # Apply preprocessing to each element in X\n",
    "        return [self.preprocess_text(text) for text in X]\n",
    "\n",
    "    def preprocess_text(self, text):\n",
    "        text = text.lower()  # Convert to lowercase\n",
    "        text = re.sub(r'[^a-zA-Z\\s]', '', text)  # Remove special characters\n",
    "        tokens = word_tokenize(text)  # Tokenize\n",
    "        filtered_tokens = [token for token in tokens if token not in self.stop_words]  # Remove stopwords\n",
    "        return ' '.join(filtered_tokens)  # Join tokens back into a single string\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec2f711b",
   "metadata": {},
   "source": [
    "##### Label Encoder Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7ffd51a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class LabelDecoder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, encoder):\n",
    "        self.encoder = encoder\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self  # Nothing to do\n",
    "\n",
    "    def transform(self, X):\n",
    "        # Assumes X is a 1D array of labels\n",
    "        return self.encoder.inverse_transform(X)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cf4128a",
   "metadata": {},
   "source": [
    "###### The Pipeline Itself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "72e2d50c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['complete_text_processing_pipeline.pkl']"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Initialize components\n",
    "text_preprocessor = TextPreprocessor()\n",
    "classifier = joblib.load('xgboost_model.pkl')  # Load your previously saved model\n",
    "\n",
    "# Define the complete pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('text_preprocessor', text_preprocessor),\n",
    "    ('vectorizer', vectorizer),\n",
    "    ('classifier', classifier)  # Decoding labels after prediction\n",
    "])\n",
    "\n",
    "# Save the complete pipeline\n",
    "joblib.dump(pipeline, 'complete_text_processing_pipeline.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a4a941f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = pipeline.predict_proba([\"I am a veterinarian\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7633d576",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.9317395e-04, 1.3577023e-02, 9.8622978e-01]], dtype=float32)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e880070a",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_class_indices = np.argmax(pred, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b2bc35b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded_predictions = label_encoder.inverse_transform(predicted_class_indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0ec94eab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['veterinarian'], dtype=object)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoded_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed2e0885",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
